{
  "metadata": {
    "experiment_name": "novelty_detection_20250919_055720",
    "created_at": "2025-09-19T06:00:25.509787",
    "device_info": {
      "device": "cuda",
      "device_name": "Tesla V100-PCIE-32GB",
      "memory_total": 34072559616,
      "memory_available": 0
    }
  },
  "experiments": [
    {
      "timestamp": "2025-09-19T06:03:17.885108",
      "config": {
        "dataset": {
          "path": "CUB_200_2011/images",
          "seen_classes": 150,
          "max_images_per_class": 100,
          "test_size": 0.3,
          "random_state": 42
        },
        "model": {
          "n_components": 50,
          "n_neighbors": 10,
          "contamination": 0.35,
          "metric": "cosine"
        },
        "preprocessing": {
          "standardize": true,
          "clip_model": "ViT-B/32"
        },
        "experiment": {
          "timestamp": "2025-09-19T06:00:25.464399",
          "device_info": {
            "device": "cuda",
            "device_name": "Tesla V100-PCIE-32GB",
            "memory_total": 34072559616,
            "memory_available": 0
          }
        }
      },
      "results": {
        "accuracy": 0.6860858720826652,
        "precision": 0.6911111111111111,
        "recall": 0.7339851652056641,
        "f1_score": 0.7119032047089601,
        "roc_auc": 0.7387804766831038,
        "specificity": 0.6324140536456365,
        "pr_auc": 0.7011278881270158,
        "fpr_at_95_tpr": 0.6615035889686437,
        "tnr_at_95_tpr": 0.3384964110313563,
        "youdens_index": 0.3706240299008967,
        "ausuc": 0.7387804766831038,
        "brier_score": 0.29514869616292716,
        "ece": 0.2324286621391363,
        "seen_accuracy": 0.0,
        "unseen_accuracy": 0.0,
        "harmonic_mean": 0.0,
        "overall_accuracy": 0.6860858720826652,
        "mean_per_class_accuracy": 0.0,
        "std_per_class_accuracy": 0.0,
        "confusion_matrix": "[[1674  973]\n [ 789 2177]]"
      },
      "model_path": "models/pca_lof_model_20250919_060315.pkl"
    }
  ]
}